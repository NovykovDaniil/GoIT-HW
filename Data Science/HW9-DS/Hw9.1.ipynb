{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = tf.keras.datasets.fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Output of the first image from the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=[8,8])\n",
    "plt.subplot(1,2,1)\n",
    "plt.imshow(x_train[1,:,:], cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of classes :  10\n",
      "Unique labels :  [0 1 2 3 4 5 6 7 8 9]\n"
     ]
    }
   ],
   "source": [
    "unique_labels = np.unique(y_train)\n",
    "\n",
    "num_classes = len(unique_labels)\n",
    "\n",
    "print('Total number of classes : ', num_classes)\n",
    "print('Unique labels : ', unique_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a neural network models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NN Classifier with Dense layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "1875/1875 [==============================] - 55s 22ms/step - loss: 0.5000 - accuracy: 0.8243 - val_loss: 0.4210 - val_accuracy: 0.8516\n",
      "Epoch 2/25\n",
      "1875/1875 [==============================] - 40s 21ms/step - loss: 0.3725 - accuracy: 0.8671 - val_loss: 0.3685 - val_accuracy: 0.8696\n",
      "Epoch 3/25\n",
      "1875/1875 [==============================] - 40s 21ms/step - loss: 0.3348 - accuracy: 0.8796 - val_loss: 0.3835 - val_accuracy: 0.8661\n",
      "Epoch 4/25\n",
      "1875/1875 [==============================] - 40s 21ms/step - loss: 0.3106 - accuracy: 0.8887 - val_loss: 0.3796 - val_accuracy: 0.8703\n",
      "Epoch 5/25\n",
      "1875/1875 [==============================] - 41s 22ms/step - loss: 0.2938 - accuracy: 0.8940 - val_loss: 0.3559 - val_accuracy: 0.8793\n",
      "Epoch 6/25\n",
      "1875/1875 [==============================] - 41s 22ms/step - loss: 0.2798 - accuracy: 0.9003 - val_loss: 0.3354 - val_accuracy: 0.8865\n",
      "Epoch 7/25\n",
      "1875/1875 [==============================] - 40s 21ms/step - loss: 0.2689 - accuracy: 0.9050 - val_loss: 0.3618 - val_accuracy: 0.8794\n",
      "Epoch 8/25\n",
      "1875/1875 [==============================] - 39s 21ms/step - loss: 0.2582 - accuracy: 0.9077 - val_loss: 0.3606 - val_accuracy: 0.8823\n",
      "Epoch 9/25\n",
      "1875/1875 [==============================] - 39s 21ms/step - loss: 0.2481 - accuracy: 0.9115 - val_loss: 0.3798 - val_accuracy: 0.8768\n",
      "Epoch 10/25\n",
      "1875/1875 [==============================] - 40s 21ms/step - loss: 0.2390 - accuracy: 0.9143 - val_loss: 0.3486 - val_accuracy: 0.8869\n",
      "Epoch 11/25\n",
      "1875/1875 [==============================] - 41s 22ms/step - loss: 0.2329 - accuracy: 0.9171 - val_loss: 0.3535 - val_accuracy: 0.8894\n",
      "Epoch 12/25\n",
      "1875/1875 [==============================] - 43s 23ms/step - loss: 0.2261 - accuracy: 0.9192 - val_loss: 0.3435 - val_accuracy: 0.8886\n",
      "Epoch 13/25\n",
      "1875/1875 [==============================] - 39s 21ms/step - loss: 0.2201 - accuracy: 0.9215 - val_loss: 0.3815 - val_accuracy: 0.8772\n",
      "Epoch 14/25\n",
      "1875/1875 [==============================] - 39s 21ms/step - loss: 0.2119 - accuracy: 0.9240 - val_loss: 0.3649 - val_accuracy: 0.8891\n",
      "Epoch 15/25\n",
      "1875/1875 [==============================] - 37s 20ms/step - loss: 0.2037 - accuracy: 0.9276 - val_loss: 0.3725 - val_accuracy: 0.8881\n",
      "Epoch 16/25\n",
      "1875/1875 [==============================] - 35s 19ms/step - loss: 0.1983 - accuracy: 0.9290 - val_loss: 0.3863 - val_accuracy: 0.8874\n",
      "Epoch 17/25\n",
      "1875/1875 [==============================] - 35s 19ms/step - loss: 0.1935 - accuracy: 0.9312 - val_loss: 0.3805 - val_accuracy: 0.8900\n",
      "Epoch 18/25\n",
      "1875/1875 [==============================] - 36s 19ms/step - loss: 0.1875 - accuracy: 0.9326 - val_loss: 0.3813 - val_accuracy: 0.8914\n",
      "Epoch 19/25\n",
      "1875/1875 [==============================] - 35s 19ms/step - loss: 0.1856 - accuracy: 0.9340 - val_loss: 0.4031 - val_accuracy: 0.8890\n",
      "Epoch 20/25\n",
      "1875/1875 [==============================] - 36s 19ms/step - loss: 0.1819 - accuracy: 0.9356 - val_loss: 0.3986 - val_accuracy: 0.8859\n",
      "Epoch 21/25\n",
      "1875/1875 [==============================] - 36s 19ms/step - loss: 0.1788 - accuracy: 0.9368 - val_loss: 0.4009 - val_accuracy: 0.8898\n",
      "Epoch 22/25\n",
      "1875/1875 [==============================] - 38s 21ms/step - loss: 0.1750 - accuracy: 0.9371 - val_loss: 0.4253 - val_accuracy: 0.8871\n",
      "Epoch 23/25\n",
      "1875/1875 [==============================] - 39s 21ms/step - loss: 0.1722 - accuracy: 0.9390 - val_loss: 0.4278 - val_accuracy: 0.8856\n",
      "Epoch 24/25\n",
      "1875/1875 [==============================] - 39s 21ms/step - loss: 0.1661 - accuracy: 0.9405 - val_loss: 0.4063 - val_accuracy: 0.8853\n",
      "Epoch 25/25\n",
      "1875/1875 [==============================] - 39s 21ms/step - loss: 0.1622 - accuracy: 0.9421 - val_loss: 0.4372 - val_accuracy: 0.8905\n",
      "Test accuracy: 0.890500009059906\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import fashion_mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, BatchNormalization\n",
    "from keras.optimizers import RMSprop\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 25\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()\n",
    "x_train = x_train.reshape((x_train.shape[0], 784))\n",
    "x_test = x_test.reshape((x_test.shape[0], 784))\n",
    "x_train = x_train.astype('float32') / 255\n",
    "x_test = x_test.astype('float32') / 255\n",
    "\n",
    "num_classes = 10\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(512, activation='relu', input_shape=(784,)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(256, activation='relu', ))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer=RMSprop(learning_rate=1e-4), metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train, batch_size=BATCH_SIZE, epochs=EPOCHS, validation_data=(x_test, y_test))\n",
    "\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NN Classifier with Conv2D and MaxPooling2D layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "938/938 [==============================] - 48s 49ms/step - loss: 0.5172 - accuracy: 0.8114 - val_loss: 0.3879 - val_accuracy: 0.8566\n",
      "Epoch 2/20\n",
      "938/938 [==============================] - 42s 45ms/step - loss: 0.3348 - accuracy: 0.8791 - val_loss: 0.3191 - val_accuracy: 0.8860\n",
      "Epoch 3/20\n",
      "938/938 [==============================] - 41s 44ms/step - loss: 0.2912 - accuracy: 0.8933 - val_loss: 0.2920 - val_accuracy: 0.8946\n",
      "Epoch 4/20\n",
      "938/938 [==============================] - 42s 45ms/step - loss: 0.2580 - accuracy: 0.9038 - val_loss: 0.2785 - val_accuracy: 0.8967\n",
      "Epoch 5/20\n",
      "938/938 [==============================] - 43s 46ms/step - loss: 0.2346 - accuracy: 0.9139 - val_loss: 0.2634 - val_accuracy: 0.9026\n",
      "Epoch 6/20\n",
      "938/938 [==============================] - 48s 51ms/step - loss: 0.2157 - accuracy: 0.9194 - val_loss: 0.2556 - val_accuracy: 0.9094\n",
      "Epoch 7/20\n",
      "938/938 [==============================] - 41s 44ms/step - loss: 0.1970 - accuracy: 0.9269 - val_loss: 0.2516 - val_accuracy: 0.9087\n",
      "Epoch 8/20\n",
      "938/938 [==============================] - 44s 47ms/step - loss: 0.1831 - accuracy: 0.9310 - val_loss: 0.2438 - val_accuracy: 0.9147\n",
      "Epoch 9/20\n",
      "938/938 [==============================] - 41s 44ms/step - loss: 0.1672 - accuracy: 0.9382 - val_loss: 0.2427 - val_accuracy: 0.9124\n",
      "Epoch 10/20\n",
      "938/938 [==============================] - 42s 44ms/step - loss: 0.1572 - accuracy: 0.9413 - val_loss: 0.2557 - val_accuracy: 0.9118\n",
      "Epoch 11/20\n",
      "938/938 [==============================] - 42s 45ms/step - loss: 0.1424 - accuracy: 0.9465 - val_loss: 0.2636 - val_accuracy: 0.9131\n",
      "Epoch 12/20\n",
      "938/938 [==============================] - 42s 45ms/step - loss: 0.1327 - accuracy: 0.9499 - val_loss: 0.2730 - val_accuracy: 0.9138\n",
      "Epoch 13/20\n",
      "938/938 [==============================] - 42s 45ms/step - loss: 0.1227 - accuracy: 0.9532 - val_loss: 0.2776 - val_accuracy: 0.9146\n",
      "Epoch 14/20\n",
      "938/938 [==============================] - 43s 45ms/step - loss: 0.1137 - accuracy: 0.9567 - val_loss: 0.2672 - val_accuracy: 0.9165\n",
      "Epoch 15/20\n",
      "938/938 [==============================] - 43s 46ms/step - loss: 0.1050 - accuracy: 0.9599 - val_loss: 0.2760 - val_accuracy: 0.9152\n",
      "Epoch 16/20\n",
      "938/938 [==============================] - 42s 45ms/step - loss: 0.1010 - accuracy: 0.9618 - val_loss: 0.3054 - val_accuracy: 0.9146\n",
      "Epoch 17/20\n",
      "938/938 [==============================] - 43s 45ms/step - loss: 0.0910 - accuracy: 0.9653 - val_loss: 0.3060 - val_accuracy: 0.9093\n",
      "Epoch 18/20\n",
      "938/938 [==============================] - 42s 44ms/step - loss: 0.0857 - accuracy: 0.9675 - val_loss: 0.3138 - val_accuracy: 0.9186\n",
      "Epoch 19/20\n",
      "938/938 [==============================] - 41s 43ms/step - loss: 0.0797 - accuracy: 0.9697 - val_loss: 0.3123 - val_accuracy: 0.9188\n",
      "Epoch 20/20\n",
      "938/938 [==============================] - 42s 44ms/step - loss: 0.0753 - accuracy: 0.9711 - val_loss: 0.3534 - val_accuracy: 0.9104\n",
      "Test accuracy: 0.9103999733924866\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import fashion_mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "BATCH_SIZE = 64\n",
    "EPOCHS = 20\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()\n",
    "x_train = x_train.reshape((x_train.shape[0], 28, 28, 1))\n",
    "x_test = x_test.reshape((x_test.shape[0], 28, 28, 1))\n",
    "x_train = x_train.astype('float32') / 255\n",
    "x_test = x_test.astype('float32') / 255\n",
    "\n",
    "num_classes = 10\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(28, 28, 1)))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Conv2D(64, kernel_size=(3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer=Adam(), metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train, batch_size=BATCH_SIZE, epochs=EPOCHS, validation_data=(x_test, y_test))\n",
    "\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test accuracy:', score[1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Conclusion\n",
    "Today we have created a neural network for classifying images from the fashion mnist dataset. We used dense layers and layers that are used in creating CNN. The result was quite good. In the first case, we got 89% accuracy on the test data, and the accuracy of the second neural network was 91.3%."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
