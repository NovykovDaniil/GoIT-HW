{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
      "29515/29515 [==============================] - 0s 4us/step\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
      "26421880/26421880 [==============================] - 264s 10us/step\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
      "5148/5148 [==============================] - 0s 0s/step\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
      "4422102/4422102 [==============================] - 55s 12us/step\n"
     ]
    }
   ],
   "source": [
    "data = tf.keras.datasets.fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Output of the first image from the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=[8,8])\n",
    "plt.subplot(1,2,1)\n",
    "plt.imshow(x_train[1,:,:], cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of classes :  10\n",
      "Unique labels :  [0 1 2 3 4 5 6 7 8 9]\n"
     ]
    }
   ],
   "source": [
    "unique_labels = np.unique(y_train)\n",
    "\n",
    "num_classes = len(unique_labels)\n",
    "\n",
    "print('Total number of classes : ', num_classes)\n",
    "print('Unique labels : ', unique_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a neural network models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NN Classifier with Dense layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "469/469 [==============================] - 36s 49ms/step - loss: 0.6387 - accuracy: 0.7732 - val_loss: 0.4263 - val_accuracy: 0.8511\n",
      "Epoch 2/20\n",
      "469/469 [==============================] - 19s 40ms/step - loss: 0.4335 - accuracy: 0.8456 - val_loss: 0.3958 - val_accuracy: 0.8557\n",
      "Epoch 3/20\n",
      "469/469 [==============================] - 19s 40ms/step - loss: 0.3871 - accuracy: 0.8607 - val_loss: 0.3727 - val_accuracy: 0.8668\n",
      "Epoch 4/20\n",
      "469/469 [==============================] - 18s 39ms/step - loss: 0.3631 - accuracy: 0.8696 - val_loss: 0.3605 - val_accuracy: 0.8659\n",
      "Epoch 5/20\n",
      "469/469 [==============================] - 18s 39ms/step - loss: 0.3439 - accuracy: 0.8761 - val_loss: 0.3424 - val_accuracy: 0.8767\n",
      "Epoch 6/20\n",
      "469/469 [==============================] - 19s 40ms/step - loss: 0.3330 - accuracy: 0.8806 - val_loss: 0.3495 - val_accuracy: 0.8751\n",
      "Epoch 7/20\n",
      "469/469 [==============================] - 18s 38ms/step - loss: 0.3227 - accuracy: 0.8837 - val_loss: 0.3370 - val_accuracy: 0.8797\n",
      "Epoch 8/20\n",
      "469/469 [==============================] - 19s 40ms/step - loss: 0.3097 - accuracy: 0.8879 - val_loss: 0.3318 - val_accuracy: 0.8819\n",
      "Epoch 9/20\n",
      "469/469 [==============================] - 19s 40ms/step - loss: 0.3005 - accuracy: 0.8905 - val_loss: 0.3329 - val_accuracy: 0.8836\n",
      "Epoch 10/20\n",
      "469/469 [==============================] - 18s 39ms/step - loss: 0.2935 - accuracy: 0.8922 - val_loss: 0.3312 - val_accuracy: 0.8819\n",
      "Epoch 11/20\n",
      "469/469 [==============================] - 18s 39ms/step - loss: 0.2849 - accuracy: 0.8954 - val_loss: 0.3318 - val_accuracy: 0.8810\n",
      "Epoch 12/20\n",
      "469/469 [==============================] - 18s 38ms/step - loss: 0.2809 - accuracy: 0.8971 - val_loss: 0.3510 - val_accuracy: 0.8737\n",
      "Epoch 13/20\n",
      "469/469 [==============================] - 19s 40ms/step - loss: 0.2758 - accuracy: 0.8996 - val_loss: 0.3292 - val_accuracy: 0.8852\n",
      "Epoch 14/20\n",
      "469/469 [==============================] - 18s 38ms/step - loss: 0.2685 - accuracy: 0.9019 - val_loss: 0.3211 - val_accuracy: 0.8863\n",
      "Epoch 15/20\n",
      "469/469 [==============================] - 18s 38ms/step - loss: 0.2613 - accuracy: 0.9024 - val_loss: 0.3179 - val_accuracy: 0.8898\n",
      "Epoch 16/20\n",
      "469/469 [==============================] - 18s 39ms/step - loss: 0.2601 - accuracy: 0.9033 - val_loss: 0.3168 - val_accuracy: 0.8843\n",
      "Epoch 17/20\n",
      "469/469 [==============================] - 18s 39ms/step - loss: 0.2565 - accuracy: 0.9062 - val_loss: 0.3170 - val_accuracy: 0.8880\n",
      "Epoch 18/20\n",
      "469/469 [==============================] - 18s 38ms/step - loss: 0.2498 - accuracy: 0.9081 - val_loss: 0.3164 - val_accuracy: 0.8889\n",
      "Epoch 19/20\n",
      "469/469 [==============================] - 18s 38ms/step - loss: 0.2483 - accuracy: 0.9086 - val_loss: 0.3275 - val_accuracy: 0.8853\n",
      "Epoch 20/20\n",
      "469/469 [==============================] - 18s 39ms/step - loss: 0.2462 - accuracy: 0.9089 - val_loss: 0.3154 - val_accuracy: 0.8878\n",
      "Test accuracy: 0.8877999782562256\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import fashion_mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "BATCH_SIZE = 128\n",
    "EPOCHS = 20\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()\n",
    "x_train = x_train.reshape((x_train.shape[0], 784))\n",
    "x_test = x_test.reshape((x_test.shape[0], 784))\n",
    "x_train = x_train.astype('float32') / 255\n",
    "x_test = x_test.astype('float32') / 255\n",
    "\n",
    "num_classes = 10\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(512, activation='relu', input_shape=(784,)))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer=Adam(), metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train, batch_size=BATCH_SIZE, epochs=EPOCHS, validation_data=(x_test, y_test))\n",
    "\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test accuracy:', score[1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NN Classifier with Conv2D and MaxPooling2D layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "469/469 [==============================] - 57s 99ms/step - loss: 0.5742 - accuracy: 0.7918 - val_loss: 0.3878 - val_accuracy: 0.8605\n",
      "Epoch 2/20\n",
      "469/469 [==============================] - 49s 103ms/step - loss: 0.3686 - accuracy: 0.8661 - val_loss: 0.3353 - val_accuracy: 0.8788\n",
      "Epoch 3/20\n",
      "469/469 [==============================] - 54s 115ms/step - loss: 0.3166 - accuracy: 0.8858 - val_loss: 0.3119 - val_accuracy: 0.8882\n",
      "Epoch 4/20\n",
      "469/469 [==============================] - 66s 141ms/step - loss: 0.2879 - accuracy: 0.8952 - val_loss: 0.2970 - val_accuracy: 0.8928\n",
      "Epoch 5/20\n",
      "469/469 [==============================] - 50s 107ms/step - loss: 0.2660 - accuracy: 0.9021 - val_loss: 0.2899 - val_accuracy: 0.8952\n",
      "Epoch 6/20\n",
      "469/469 [==============================] - 48s 103ms/step - loss: 0.2487 - accuracy: 0.9082 - val_loss: 0.2843 - val_accuracy: 0.8969\n",
      "Epoch 7/20\n",
      "469/469 [==============================] - 51s 110ms/step - loss: 0.2292 - accuracy: 0.9153 - val_loss: 0.2533 - val_accuracy: 0.9077\n",
      "Epoch 8/20\n",
      "469/469 [==============================] - 48s 102ms/step - loss: 0.2166 - accuracy: 0.9198 - val_loss: 0.2591 - val_accuracy: 0.9060\n",
      "Epoch 9/20\n",
      "469/469 [==============================] - 48s 103ms/step - loss: 0.2020 - accuracy: 0.9252 - val_loss: 0.2513 - val_accuracy: 0.9115\n",
      "Epoch 10/20\n",
      "469/469 [==============================] - 47s 101ms/step - loss: 0.1879 - accuracy: 0.9306 - val_loss: 0.2427 - val_accuracy: 0.9134\n",
      "Epoch 11/20\n",
      "469/469 [==============================] - 47s 100ms/step - loss: 0.1778 - accuracy: 0.9335 - val_loss: 0.2484 - val_accuracy: 0.9112\n",
      "Epoch 12/20\n",
      "469/469 [==============================] - 50s 106ms/step - loss: 0.1681 - accuracy: 0.9377 - val_loss: 0.2449 - val_accuracy: 0.9143\n",
      "Epoch 13/20\n",
      "469/469 [==============================] - 48s 102ms/step - loss: 0.1562 - accuracy: 0.9416 - val_loss: 0.2408 - val_accuracy: 0.9150\n",
      "Epoch 14/20\n",
      "469/469 [==============================] - 46s 99ms/step - loss: 0.1462 - accuracy: 0.9452 - val_loss: 0.2403 - val_accuracy: 0.9136\n",
      "Epoch 15/20\n",
      "469/469 [==============================] - 49s 105ms/step - loss: 0.1393 - accuracy: 0.9485 - val_loss: 0.2461 - val_accuracy: 0.9142\n",
      "Epoch 16/20\n",
      "469/469 [==============================] - 52s 111ms/step - loss: 0.1294 - accuracy: 0.9517 - val_loss: 0.2614 - val_accuracy: 0.9169\n",
      "Epoch 17/20\n",
      "469/469 [==============================] - 46s 99ms/step - loss: 0.1213 - accuracy: 0.9539 - val_loss: 0.2500 - val_accuracy: 0.9162\n",
      "Epoch 18/20\n",
      "469/469 [==============================] - 47s 101ms/step - loss: 0.1144 - accuracy: 0.9570 - val_loss: 0.2577 - val_accuracy: 0.9153\n",
      "Epoch 19/20\n",
      "469/469 [==============================] - 48s 102ms/step - loss: 0.1071 - accuracy: 0.9596 - val_loss: 0.2823 - val_accuracy: 0.9121\n",
      "Epoch 20/20\n",
      "469/469 [==============================] - 46s 99ms/step - loss: 0.0992 - accuracy: 0.9621 - val_loss: 0.2765 - val_accuracy: 0.9140\n",
      "Test accuracy: 0.9139999747276306\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import fashion_mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "BATCH_SIZE = 128\n",
    "EPOCHS = 20\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()\n",
    "x_train = x_train.reshape((x_train.shape[0], 28, 28, 1))\n",
    "x_test = x_test.reshape((x_test.shape[0], 28, 28, 1))\n",
    "x_train = x_train.astype('float32') / 255\n",
    "x_test = x_test.astype('float32') / 255\n",
    "\n",
    "num_classes = 10\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(28, 28, 1)))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Conv2D(64, kernel_size=(3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer=Adam(), metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train, batch_size=BATCH_SIZE, epochs=EPOCHS, validation_data=(x_test, y_test))\n",
    "\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test accuracy:', score[1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Conclusion\n",
    "Today we have created a neural network for classifying images from the fashion mnist dataset. We used dense layers and layers that are used in creating CNN. The result was quite good. In the first case, we got 89% accuracy on the test data, and the accuracy of the second neural network was 91.3%."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
